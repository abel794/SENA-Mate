SENA-Mate API

Versi√≥n: 1.0
Archivo principal: main.py
Objetivo: API para generar respuestas de IA y checklists de Pull Requests, con trazas (prints) para depuraci√≥n y validaciones.

1Ô∏è‚É£ Requisitos

Python ‚â• 3.10

pip

.env con variable HF_TOKEN (token Hugging Face o OpenAI compatible con router HF)

Opcional: variable CHAT_MODEL para elegir modelo (por defecto "openai/gpt-oss-20b")

2Ô∏è‚É£ Instalaci√≥n

Clonar o descargar el repositorio:

git clone <URL_DEL_REPOSITORIO>
cd SENA-Mate


Crear entorno virtual:

python -m venv .venv


Activar entorno:

Windows:

.venv\Scripts\activate


Linux / macOS:

source .venv/bin/activate


Instalar dependencias:

pip install fastapi uvicorn pydantic openai python-dotenv

3Ô∏è‚É£ Estructura de carpetas
SENA-Mate/
‚îú‚îÄ‚îÄ main.py                  # C√≥digo principal de la API
‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îî‚îÄ‚îÄ prompt.json          # Prompt inicial y few_shots
‚îú‚îÄ‚îÄ .env                     # Variables de entorno (HF_TOKEN)
‚îî‚îÄ‚îÄ README.md

4Ô∏è‚É£ Configuraci√≥n del .env
HF_TOKEN=TU_TOKEN_AQUI
CHAT_MODEL=openai/gpt-oss-20b  # Opcional


‚ö†Ô∏è Nota de seguridad: No compartas tu HF_TOKEN p√∫blicamente.

5Ô∏è‚É£ Uso de la API
Iniciar servidor
uvicorn main:app --reload --port 8000

Endpoints
GET /

Retorna mensaje de salud de la API.

{
  "message": "SENA-Mate API funcionando (prompt.json integrado)"
}

POST /ask

Valida entrada con Pydantic (question m√≠nima de 5 caracteres)

Llama al modelo configurado (CHAT_MODEL)

Devuelve respuesta de IA y metadatos

Ejemplo request:

{
  "question": "¬øQu√© es Python?"
}


Ejemplo response:

{
  "question": "¬øQu√© es Python?",
  "answer": "Python es un lenguaje de programaci√≥n de alto nivel...",
  "prompt_used": "Eres un asistente que ayuda con tareas t√©cnicas...",
  "source": "openai/gpt-oss-20b"
}

POST /hf_ask

Similar a /ask, enfocado en Hugging Face

Incluye trazas y logs detallados

POST /prepPR

Valida entrada (title y description)

Genera checklist combinando base + coincidencias en few_shots del prompt.json

Devuelve JSON listo para frontend

Ejemplo request:

{
  "title": "Agregar autenticaci√≥n JWT",
  "description": "Implementar login seguro con tokens JWT para usuarios"
}


Ejemplo response:

{
  "title": "Agregar autenticaci√≥n JWT",
  "description": "Implementar login seguro con tokens JWT para usuarios",
  "checklist": [
    "T√≠tulo claro y descriptivo",
    "Descripci√≥n con contexto",
    "C√≥digo probado y funcional",
    "Documentaci√≥n actualizada",
    "Cumple con est√°ndares del proyecto"
  ],
  "matched_templates": [],
  "prompt_used": "Eres un asistente que ayuda con tareas t√©cnicas...",
  "source": "prompt.json"
}

6Ô∏è‚É£ Logs y depuraci√≥n

Cada endpoint imprime trazas con print:

Entradas recibidas

Keywords extra√≠das

Templates evaluados

Checklist final

Errores y excepciones

Esto permite seguimiento paso a paso en desarrollo.

7Ô∏è‚É£ Seguridad

No se imprime HF_TOKEN completo.

Validaciones de entradas con Pydantic (min_length, campos requeridos).

Manejo de errores con HTTPException.

8Ô∏è‚É£ Integraci√≥n Frontend

Desde React o cualquier frontend:

Usar fetch o axios para llamar endpoints

Mostrar answer o checklist seg√∫n endpoint

Ejemplo b√°sico con fetch:

const response = await fetch("http://127.0.0.1:8000/ask", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ question: "¬øQu√© es Python?" })
});
const data = await response.json();
console.log(data.answer);

9Ô∏è‚É£ Documentaci√≥n autom√°tica

FastAPI genera documentaci√≥n OpenAPI:

http://127.0.0.1:8000/docs

http://127.0.0.1:8000/redoc

10Ô∏è‚É£ Notas finales

Mantener prompts/prompt.json actualizado con few_shots para mejorar resultados de checklist.

Ajustar CHAT_MODEL seg√∫n disponibilidad y necesidades.

call_chat_model centraliza la llamada al modelo y maneja logs y errores.


# üìö SENA-Mate API (Backend)

SENA-Mate API es un asistente virtual dise√±ado para aprendices e instructores del SENA.  
Funciona con **FastAPI** y un modelo de IA alojado en **Hugging Face** (o cualquier otro proveedor compatible con la API de OpenAI).  
Permite hacer preguntas y recibir respuestas inteligentes, as√≠ como generar checklists para Pull Requests.

---

## üìÇ Estructura del proyecto

SENA-Mate/
‚îú‚îÄ‚îÄ main.py # Backend con FastAPI
‚îú‚îÄ‚îÄ prompts/
‚îÇ ‚îî‚îÄ‚îÄ prompt.json # Archivo con el prompt y ejemplos
‚îú‚îÄ‚îÄ .env # Variables de entorno (no subir a GitHub)
‚îî‚îÄ‚îÄ README.md # Documentaci√≥n

yaml
Copiar
Editar

---

## üõ† 1. Requisitos previos

Antes de empezar, aseg√∫rate de tener instalado:

- [Python 3.9 o superior](https://www.python.org/downloads/)
- [pip](https://pip.pypa.io/en/stable/installation/)
- [Hugging Face account](https://huggingface.co/) (para obtener el **HF_TOKEN** gratuito)

---

## üöÄ 2. Instalaci√≥n

1Ô∏è‚É£ **Clonar el repositorio**

```bash
git clone https://github.com/TU-USUARIO/SENA-Mate.git
cd SENA-Mate
2Ô∏è‚É£ Crear un entorno virtual

bash
Copiar
Editar
python -m venv .venv
3Ô∏è‚É£ Activar el entorno

En Windows:

bash
Copiar
Editar
.venv\Scripts\activate
En Linux / Mac:

bash
Copiar
Editar
source .venv/bin/activate
4Ô∏è‚É£ Instalar dependencias

bash
Copiar
Editar
pip install fastapi uvicorn pydantic openai python-dotenv
üîë 3. Configuraci√≥n de variables de entorno
Crear un archivo .env en la carpeta ra√≠z del proyecto:

ini
Copiar
Editar
HF_TOKEN=tu_token_de_huggingface
CHAT_MODEL=openai/gpt-oss-20b
Nota:

HF_TOKEN es tu clave de Hugging Face (puedes generarla en huggingface.co/settings/tokens).

CHAT_MODEL es el modelo que quieres usar.

üìÑ 4. Archivo prompt.json
Ubicado en prompts/prompt.json
Aqu√≠ defines la personalidad del asistente y ejemplos de c√≥mo debe responder.

Ejemplo:

json
Copiar
Editar
{
    "system": "Eres SENA-Mate, un asistente virtual para aprendices e instructores del SENA. Genera checklists claros, rutas de aprendizaje y retroalimentaci√≥n breve.",
    "few_shots": [
        {
            "question": "¬øQu√© es Python?",
            "answer": "Es un lenguaje de programaci√≥n muy usado en ciencia de datos y desarrollo web."
        },
        {
            "question": "Dame una frase del d√≠a",
            "answer": "El √©xito es la suma de peque√±os esfuerzos repetidos d√≠a tras d√≠a."
        }
    ]
}
üñ• 5. Ejecuci√≥n del servidor
bash
Copiar
Editar
uvicorn main:app --reload --port 8000
Esto levantar√° el backend en:

cpp
Copiar
Editar
http://127.0.0.1:8000
üìå 6. Endpoints disponibles
1Ô∏è‚É£ /hf_ask (POST)
Descripci√≥n: Recibe una pregunta y devuelve una respuesta de la IA.

Ejemplo de request:

json
Copiar
Editar
{
    "question": "hola dime una frase del dia"
}
Ejemplo de response:

json
Copiar
Editar
{
    "answer": "La perseverancia es la clave del √©xito.",
    "confidence": 0.95,
    "source": "huggingface"
}
2Ô∏è‚É£ /prepPR (POST)
Descripci√≥n: Genera un checklist para un Pull Request.

Ejemplo de request:

json
Copiar
Editar
{
    "title": "Mejora de login",
    "description": "Se a√±adi√≥ validaci√≥n de usuario y manejo de errores."
}
Ejemplo de response:

json
Copiar
Editar
{
    "checklist": [
        "Validar credenciales correctamente",
        "Probar recuperaci√≥n de contrase√±a",
        "Verificar que los mensajes de error sean claros"
    ]
}
‚ö† 7. Manejo de errores y validaciones
Validaci√≥n de entradas con Pydantic (asegura que question, title, description sean strings v√°lidos).

HTTPException para devolver errores claros en formato JSON.

Logs en consola (print) para mostrar:

Preguntas recibidas.

Respuestas generadas.

Errores detectados.

üîó 8. Integraci√≥n con el Frontend
Puedes conectar este backend a cualquier frontend (React, Vue, Angular o incluso HTML simple).

Ejemplo en React con fetch:

javascript
Copiar
Editar
async function preguntar() {
  const resp = await fetch("http://127.0.0.1:8000/hf_ask", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ question: "Hola, dame una frase del d√≠a" })
  });
  const data = await resp.json();
  console.log(data.answer);
}
üß™ 9. Probar en Swagger UI
FastAPI genera documentaci√≥n autom√°tica en:

arduino
Copiar
Editar
http://127.0.0.1:8000/docs
Ah√≠ puedes enviar peticiones de prueba sin necesidad de Postman.

üìú 10. Notas finales
No subas el archivo .env a GitHub.

Puedes cambiar el modelo de IA modificando CHAT_MODEL en .env.

Si quieres usar OpenAI, instala openai y cambia la inicializaci√≥n en main.py.

üë®‚Äçüíª Autor
Abel Moreno
Brajhan medina
Sebastian lizcano

Proyecto de aprendizaje para SENA